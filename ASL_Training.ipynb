{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "u7ek08KSS_C_",
        "outputId": "0a72e953-a6cb-483f-ab9e-3345d33229e0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import subprocess\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "def install_dependencies():\n",
        "    \"\"\"Menginstall library yang diperlukan.\"\"\"\n",
        "    print(\"üîÑ Menginstall library 'kaggle' dan 'split-folders'...\")\n",
        "    subprocess.check_call(['pip', 'install', '-q', 'kaggle', 'split-folders'])\n",
        "    print(\"‚úÖ Library berhasil diinstall.\")\n",
        "\n",
        "def setup_kaggle_api():\n",
        "    \"\"\"Menangani upload token kaggle.json dan konfigurasi.\"\"\"\n",
        "    print(\"\\nüìÇ Silakan upload file 'kaggle.json' Anda sekarang:\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if 'kaggle.json' not in uploaded:\n",
        "        print(\"‚ùå Error: File 'kaggle.json' tidak ditemukan. Harap upload file yang benar.\")\n",
        "        return False\n",
        "\n",
        "    print(\"üîê Mengkonfigurasi API Token...\")\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "    print(\"‚úÖ Konfigurasi Kaggle API selesai.\")\n",
        "    return True\n",
        "\n",
        "def download_and_unzip():\n",
        "    \"\"\"Mendownload dataset ASL Alphabet dan mengekstraknya.\"\"\"\n",
        "    dataset_name = \"grassknoted/asl-alphabet\"\n",
        "    zip_file = \"asl-alphabet.zip\"\n",
        "\n",
        "    print(f\"\\n‚¨áÔ∏è Sedang mendownload dataset '{dataset_name}' dari Kaggle...\")\n",
        "    subprocess.run(['kaggle', 'datasets', 'download', '-d', dataset_name], check=True)\n",
        "\n",
        "    if os.path.exists(zip_file):\n",
        "        print(\"üì¶ Sedang mengekstrak dataset (ini mungkin memakan waktu beberapa saat)...\")\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"raw_data\")\n",
        "        print(\"‚úÖ Ekstraksi selesai.\")\n",
        "\n",
        "        os.remove(zip_file)\n",
        "        return True\n",
        "    else:\n",
        "        print(\"‚ùå Gagal mendownload dataset.\")\n",
        "        return False\n",
        "\n",
        "def split_dataset():\n",
        "    \"\"\"Membagi dataset menjadi Train, Validation, dan Test.\"\"\"\n",
        "    import splitfolders\n",
        "\n",
        "    input_folder = \"raw_data/asl_alphabet_train/asl_alphabet_train\"\n",
        "    output_folder = \"asl_split_data\"\n",
        "\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"‚ùå Folder input tidak ditemukan di: {input_folder}\")\n",
        "        print(\"   Mengecek struktur folder 'raw_data'...\")\n",
        "        print(os.listdir(\"raw_data\"))\n",
        "        return\n",
        "\n",
        "    print(f\"\\n‚úÇÔ∏è Membagi dataset menjadi: Train (80%), Val (10%), Test (10%)...\")\n",
        "    print(\"   Proses ini akan menyalin dan mengacak file gambar, mohon tunggu...\")\n",
        "\n",
        "    splitfolders.ratio(\n",
        "        input_folder,\n",
        "        output=output_folder,\n",
        "        seed=1337,\n",
        "        ratio=(.8, .1, .1), # 80% Train, 10% Val, 10% Test\n",
        "        group_prefix=None\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Selesai! Dataset siap digunakan di folder: '{output_folder}'\")\n",
        "    print(f\"   Struktur folder: {os.listdir(output_folder)}\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        install_dependencies()\n",
        "        if setup_kaggle_api():\n",
        "            if download_and_unzip():\n",
        "                split_dataset()\n",
        "                print(\"\\nüéâ Semua proses berhasil! Anda siap untuk training model.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Terjadi kesalahan: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1o8b6o9UVTJ",
        "outputId": "c6521ca6-c2bb-453f-ebbe-9a2c01f5160d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "def create_data_generators():\n",
        "    base_dir = 'asl_split_data'\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "    val_dir = os.path.join(base_dir, 'val')\n",
        "    test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "    IMG_HEIGHT = 224  # Standar MobileNetV2\n",
        "    IMG_WIDTH = 224\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    print(\"üîÑ Mengkonfigurasi ImageDataGenerator...\")\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    print(\"‚úÖ Generator dikonfigurasi.\")\n",
        "    print(\"üìÇ Memuat data dari direktori...\")\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', # Multiclass classification\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    validation_generator = val_test_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = val_test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    if os.path.exists('asl_split_data'):\n",
        "        train_gen, val_gen, test_gen = create_data_generators()\n",
        "\n",
        "        print(f\"\\nüè∑Ô∏è Kelas ditemukan ({len(train_gen.class_indices)}):\")\n",
        "        labels = list(train_gen.class_indices.keys())\n",
        "        print(labels[:10], \"... dan lainnya.\")\n",
        "\n",
        "        print(\"\\n‚úÖ Siap untuk training dengan MobileNetV2!\")\n",
        "    else:\n",
        "        print(\"‚ùå Error: Folder 'asl_split_data' tidak ditemukan.\")\n",
        "        print(\"   Jalankan script 'prepare_asl_dataset.py' terlebih dahulu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P2Sa9O2WZkKD",
        "outputId": "ad4e37b0-3300-43b9-c301-2672492639e4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(num_classes=29, input_shape=(224, 224, 3)):\n",
        "    \"\"\"\n",
        "    Membangun model Transfer Learning menggunakan MobileNetV2.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Jumlah kelas output (ASL Alphabet biasanya 29).\n",
        "        input_shape (tuple): Dimensi gambar input (224, 224, 3).\n",
        "\n",
        "    Returns:\n",
        "        model: Model Keras yang sudah dikompilasi.\n",
        "    \"\"\"\n",
        "\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_model(num_classes=29)\n",
        "\n",
        "    print(\"‚úÖ Model MobileNetV2 berhasil dibangun dan dikompilasi.\")\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JM1K474fZ0i6",
        "outputId": "5381bbf0-cc15-459f-89a3-03767d9bf820"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import files\n",
        "try:\n",
        "    from preprocess_asl_data import create_data_generators\n",
        "    from model_asl_mobilenet import build_model\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Error: Pastikan file 'preprocess_asl_data.py' dan 'model_asl_mobilenet.py' sudah ada.\")\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Membuat visualisasi grafik Akurasi dan Loss.\n",
        "    \"\"\"\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot Akurasi\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def run_training():\n",
        "    print(\"Memulai persiapan data...\")\n",
        "    train_gen, val_gen, test_gen = create_data_generators()\n",
        "\n",
        "    num_classes = train_gen.num_classes\n",
        "    print(f\"Terdeteksi {num_classes} kelas.\")\n",
        "\n",
        "    print(\"Membangun model MobileNetV2...\")\n",
        "    model = build_model(num_classes=num_classes)\n",
        "\n",
        "    checkpoint_path = \"best_asl_model.keras\"\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"Mulai proses training selama 20 Epoch...\")\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=15,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\n Mengevaluasi model pada Test Set...\")\n",
        "    test_loss, test_acc = model.evaluate(test_gen)\n",
        "    print(f\"   Test Accuracy: {test_acc*100:.2f}%\")\n",
        "    print(f\"   Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    print(\"\\nMenampilkan grafik hasil training...\")\n",
        "    plot_training_history(history)\n",
        "\n",
        "    print(f\"\\nMengunduh file model '{checkpoint_path}' ke komputer lokal...\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        files.download(checkpoint_path)\n",
        "    else:\n",
        "        print(\"File model tidak ditemukan untuk didownload.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_training()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
